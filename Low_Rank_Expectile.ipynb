{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1IfzZyH0SMUQhtWlt6FlyzgemIO6JtiHl",
      "authorship_tag": "ABX9TyM/BGUMWgX1VCh5PzETbCe/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haytham918/low-rank-expectile/blob/main/Low_Rank_Expectile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "saCLAZMMxjWH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import matplotlib as plot\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv(\"/content/drive/MyDrive/low-rank-expectile/heartrate_seconds_merged.csv\")\n",
        "# Convert the 'Time' column to datetime format\n",
        "df['Time'] = pd.to_datetime(df['Time'])\n"
      ],
      "metadata": {
        "id": "IXJmn6cF1342"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_tenmin_df = df.groupby(['Id', pd.Grouper(key='Time', freq='5T')])['Value'].mean().unstack()\n",
        "user_tenmin_matrix = user_tenmin_df.values\n",
        "# print(user_tenmin_df)"
      ],
      "metadata": {
        "id": "U0Y7-t7pCfQ0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan_matrix = np.isnan(user_tenmin_matrix)\n",
        "print(\"Matrix Entry Number: \", user_tenmin_matrix.shape[0] * user_tenmin_matrix.shape[1])\n",
        "print(\"Nan Count: \", np.sum(nan_matrix))\n",
        "print(user_tenmin_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHynihEq3T9Z",
        "outputId": "f9c736b4-2c70-4a14-a19c-63d73ef189e3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Entry Number:  123718\n",
            "Nan Count:  56200\n",
            "Time        2016-04-12 00:00:00  2016-04-12 00:05:00  2016-04-12 00:10:00  \\\n",
            "Id                                                                          \n",
            "2022484408                  NaN                  NaN                  NaN   \n",
            "2026352035                  NaN                  NaN                  NaN   \n",
            "2347167796                  NaN                  NaN                  NaN   \n",
            "4020332650            66.000000            70.491071            64.460870   \n",
            "4388161847                  NaN                  NaN                  NaN   \n",
            "4558609924                  NaN                  NaN                  NaN   \n",
            "5553957443            58.185185            58.384615            59.148148   \n",
            "5577150313            47.740741            48.680000            48.346154   \n",
            "6117666160                  NaN                  NaN                  NaN   \n",
            "6775888955                  NaN                  NaN                  NaN   \n",
            "6962181067            74.107143            72.080000            74.200000   \n",
            "7007744171                  NaN                  NaN                  NaN   \n",
            "8792009665                  NaN                  NaN                  NaN   \n",
            "8877689391                  NaN                  NaN                  NaN   \n",
            "\n",
            "Time        2016-04-12 00:15:00  2016-04-12 00:20:00  2016-04-12 00:25:00  \\\n",
            "Id                                                                          \n",
            "2022484408                  NaN                  NaN                  NaN   \n",
            "2026352035                  NaN                  NaN                  NaN   \n",
            "2347167796                  NaN                  NaN                  NaN   \n",
            "4020332650            65.000000            76.641026            60.056604   \n",
            "4388161847                  NaN                  NaN                  NaN   \n",
            "4558609924                  NaN                  NaN                  NaN   \n",
            "5553957443            59.633333            55.038462            55.740741   \n",
            "5577150313            49.518519            49.840000            48.961538   \n",
            "6117666160                  NaN                  NaN                  NaN   \n",
            "6775888955                  NaN                  NaN                  NaN   \n",
            "6962181067            74.518519            74.160000            79.303030   \n",
            "7007744171                  NaN                  NaN                  NaN   \n",
            "8792009665                  NaN                  NaN                  NaN   \n",
            "8877689391                  NaN                  NaN                  NaN   \n",
            "\n",
            "Time        2016-04-12 00:30:00  2016-04-12 00:35:00  2016-04-12 00:40:00  \\\n",
            "Id                                                                          \n",
            "2022484408                  NaN                  NaN                  NaN   \n",
            "2026352035                  NaN                  NaN                  NaN   \n",
            "2347167796                  NaN                  NaN                  NaN   \n",
            "4020332650            62.469565            63.000000            63.000000   \n",
            "4388161847                  NaN                  NaN                  NaN   \n",
            "4558609924                  NaN                  NaN                  NaN   \n",
            "5553957443            57.520000            57.461538            57.200000   \n",
            "5577150313            50.375000            50.461538            48.333333   \n",
            "6117666160                  NaN                  NaN                  NaN   \n",
            "6775888955                  NaN                  NaN                  NaN   \n",
            "6962181067            70.000000            67.760000            68.851852   \n",
            "7007744171                  NaN                  NaN                  NaN   \n",
            "8792009665                  NaN                  NaN                  NaN   \n",
            "8877689391                  NaN                  NaN                  NaN   \n",
            "\n",
            "Time        2016-04-12 00:45:00  ...  2016-05-12 15:35:00  \\\n",
            "Id                               ...                        \n",
            "2022484408                  NaN  ...            64.361111   \n",
            "2026352035                  NaN  ...                  NaN   \n",
            "2347167796                  NaN  ...                  NaN   \n",
            "4020332650            66.625767  ...                  NaN   \n",
            "4388161847                  NaN  ...                  NaN   \n",
            "4558609924                  NaN  ...            69.054054   \n",
            "5553957443            58.500000  ...                  NaN   \n",
            "5577150313            48.875000  ...                  NaN   \n",
            "6117666160                  NaN  ...                  NaN   \n",
            "6775888955                  NaN  ...                  NaN   \n",
            "6962181067            71.304348  ...                  NaN   \n",
            "7007744171                  NaN  ...                  NaN   \n",
            "8792009665                  NaN  ...                  NaN   \n",
            "8877689391                  NaN  ...                  NaN   \n",
            "\n",
            "Time        2016-05-12 15:40:00  2016-05-12 15:45:00  2016-05-12 15:50:00  \\\n",
            "Id                                                                          \n",
            "2022484408            78.885714            71.090909                  NaN   \n",
            "2026352035                  NaN                  NaN                  NaN   \n",
            "2347167796                  NaN                  NaN                  NaN   \n",
            "4020332650                  NaN                  NaN                  NaN   \n",
            "4388161847                  NaN                  NaN                  NaN   \n",
            "4558609924            79.176471            79.000000            70.684211   \n",
            "5553957443                  NaN                  NaN                  NaN   \n",
            "5577150313                  NaN                  NaN                  NaN   \n",
            "6117666160                  NaN                  NaN                  NaN   \n",
            "6775888955                  NaN                  NaN                  NaN   \n",
            "6962181067                  NaN                  NaN                  NaN   \n",
            "7007744171                  NaN                  NaN                  NaN   \n",
            "8792009665                  NaN                  NaN                  NaN   \n",
            "8877689391                  NaN                  NaN                  NaN   \n",
            "\n",
            "Time        2016-05-12 15:55:00  2016-05-12 16:00:00  2016-05-12 16:05:00  \\\n",
            "Id                                                                          \n",
            "2022484408                  NaN                  NaN                  NaN   \n",
            "2026352035                  NaN                  NaN                  NaN   \n",
            "2347167796                  NaN                  NaN                  NaN   \n",
            "4020332650                  NaN                  NaN                  NaN   \n",
            "4388161847                  NaN                  NaN                  NaN   \n",
            "4558609924                 76.5            72.764706            75.651163   \n",
            "5553957443                  NaN                  NaN                  NaN   \n",
            "5577150313                  NaN                  NaN                  NaN   \n",
            "6117666160                  NaN                  NaN                  NaN   \n",
            "6775888955                  NaN                  NaN                  NaN   \n",
            "6962181067                  NaN                  NaN                  NaN   \n",
            "7007744171                  NaN                  NaN                  NaN   \n",
            "8792009665                  NaN                  NaN                  NaN   \n",
            "8877689391                  NaN                  NaN                  NaN   \n",
            "\n",
            "Time        2016-05-12 16:10:00  2016-05-12 16:15:00  2016-05-12 16:20:00  \n",
            "Id                                                                         \n",
            "2022484408                  NaN                  NaN                  NaN  \n",
            "2026352035                  NaN                  NaN                  NaN  \n",
            "2347167796                  NaN                  NaN                  NaN  \n",
            "4020332650                  NaN                  NaN                  NaN  \n",
            "4388161847                  NaN                  NaN                  NaN  \n",
            "4558609924            77.288889            73.921053                 76.0  \n",
            "5553957443                  NaN                  NaN                  NaN  \n",
            "5577150313                  NaN                  NaN                  NaN  \n",
            "6117666160                  NaN                  NaN                  NaN  \n",
            "6775888955                  NaN                  NaN                  NaN  \n",
            "6962181067                  NaN                  NaN                  NaN  \n",
            "7007744171                  NaN                  NaN                  NaN  \n",
            "8792009665                  NaN                  NaN                  NaN  \n",
            "8877689391                  NaN                  NaN                  NaN  \n",
            "\n",
            "[14 rows x 8837 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into trainig/validation and exclude missing values\n",
        "train_data, val_data, train_mask, val_mask = train_test_split(user_tenmin_matrix, nan_matrix, test_size=0.2, random_state=445)\n",
        "\n",
        "\n",
        "# Create Tensors based on train/val data\n",
        "train_tensor = torch.tensor(train_data, dtype=torch.float32)\n",
        "print(train_tensor)\n",
        "print(train_mask)\n",
        "val_tensor = torch.tensor(val_data, dtype=torch.float32)\n",
        "\n",
        "\n",
        "# Model definition\n",
        "class LRModel(nn.Module):\n",
        "  def __init__(self, number_users, number_times, rank):\n",
        "    super().__init__()\n",
        "    self.user_factors = nn.Embedding(number_users, rank)\n",
        "    self.times_factors = nn.Embedding(number_times, rank)\n",
        "\n",
        "    self.user_bias = nn.Embedding(number_users, 1)\n",
        "    self.times_bias = nn.Embedding(number_times, 1)\n",
        "\n",
        "    # Initializing the bias terms to zeros\n",
        "    self.user_bias.weight.data.fill_(0.)\n",
        "    self.times_bias.weight.data.fill_(0.)\n",
        "\n",
        "\n",
        "  # Define forward propagation\n",
        "  def forward(self, user, times):\n",
        "    # print(self.user_factors(user).shape)\n",
        "    # print(self.times_factors(times).shape)\n",
        "    pred = self.user_factors(user) * self.times_factors(times)\n",
        "    pred = pred.sum(1, keepdim=False)\n",
        "    pred += self.user_bias(user).squeeze() + self.times_bias(times).squeeze()\n",
        "    return pred\n",
        "\n",
        "# Define Loss function excluding missing values\n",
        "def loss_func(predicted, actual, mask, tau):\n",
        "    # print(predicted.shape, actual.shape, mask.shape)\n",
        "    invert_mask = ~mask\n",
        "    # print(predicted[invert_mask].shape, actual[invert_mask].shape)\n",
        "    loss = nn.MSELoss()\n",
        "    return loss(predicted[invert_mask].view(-1), actual[invert_mask].view(-1))\n",
        "    invert_mask = ~mask\n",
        "    print(predicted[invert_mask].shape, actual[invert_mask].shape)\n",
        "\n",
        "    ### With Custom Loss Function\n",
        "    # loss = 0\n",
        "    # invert_mask = invert_mask.reshape(-1)\n",
        "    # count = 0\n",
        "    # for i in range(predicted.shape[0]):\n",
        "    #   if(invert_mask[i]):\n",
        "    #     count += 1\n",
        "    #     difference = actual[i] - predicted[i]\n",
        "    #     loss += tau * difference ** 2 if difference >= 0 else (1-tau) * difference**2\n",
        "    # # return loss(predicted[invert_mask].view(-1), actual[invert_mask].view(-1))\n",
        "    # loss /= count\n",
        "    # return loss\n",
        "\n",
        "# Define parameters in our case\n",
        "number_users, number_times = train_data.shape\n",
        "rank = 6\n",
        "model = LRModel(number_users, number_times, rank)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Epochs and CheckpointPath\n",
        "number_epochs = 300\n",
        "\n",
        "global_best_loss = float('inf')\n",
        "best_epoch = 0\n",
        "\n",
        "print(val_mask.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWwzjaBHWdVR",
        "outputId": "b1c05887-d837-4363-8b3a-36aa003b5dd5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
            "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
            "        [    nan,     nan,     nan,  ..., 77.2889, 73.9211, 76.0000],\n",
            "        ...,\n",
            "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
            "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
            "        [66.0000, 70.4911, 64.4609,  ...,     nan,     nan,     nan]])\n",
            "[[ True  True  True ...  True  True  True]\n",
            " [ True  True  True ...  True  True  True]\n",
            " [ True  True  True ... False False False]\n",
            " ...\n",
            " [ True  True  True ...  True  True  True]\n",
            " [ True  True  True ...  True  True  True]\n",
            " [False False False ...  True  True  True]]\n",
            "(3, 8837)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "for epoch in range(number_epochs):\n",
        "  user_indices = torch.arange(number_users).repeat_interleave(number_times)\n",
        "  time_indices = torch.arange(number_times).repeat(number_users)\n",
        "  output = model(user_indices, time_indices)\n",
        "\n",
        "  # Calculate loss\n",
        "  train_tensor_flat = train_tensor.view(-1)\n",
        "  train_mask_flat = train_mask.reshape(-1)\n",
        "  training_loss = loss_func(output, train_tensor_flat, train_mask_flat, 0.6)\n",
        "  if(epoch % 10 == 0):\n",
        "    print(f\"Training Epoch {epoch} loss: \", training_loss)\n",
        "\n",
        "  # Backward\n",
        "  optimizer.zero_grad()\n",
        "  training_loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    validation_num_user, validation_num_times = val_tensor.shape\n",
        "    validation_user_indices = torch.arange(validation_num_user).repeat_interleave(validation_num_times)\n",
        "    validation_time_indices = torch.arange(validation_num_times).repeat(validation_num_user)\n",
        "    validation_output = model(validation_user_indices, validation_time_indices)\n",
        "    validation_loss = loss_func(validation_output, val_tensor.view(-1), val_mask.reshape(-1), 0.6)\n",
        "\n",
        "  # print(f\"Epoch [{epoch + 1}/{number_epochs}]: Training Loss: {training_loss.item()}; Validation Loss: {validation_loss.item()}\")\n",
        "\n",
        "  if validation_loss < global_best_loss:\n",
        "      global_best_loss = validation_loss\n",
        "      best_epoch = epoch\n",
        "      # torch.save({\"Epoch\": epoch, \"Model_state_dict\": model.state_dict(), \"Optimizer_state_dict\": optimizer.state_dict(), \"Loss\": validation_loss},\n",
        "      #            f\"/content/drive/MyDrive/low-rank-expectile/checkpoints/model_checkpoint_epoch{epoch}.pt\")\n",
        "\n",
        "print(\"Best Validation Epoch: \", best_epoch + 1)\n",
        "print(\"Best Validation Loss: \", global_best_loss)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "ekyhksG0W7lA",
        "outputId": "97f67230-fd79-4afb-837e-9db90a1a53e9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Epoch 0 loss:  tensor(3531.6572, grad_fn=<DivBackward0>)\n",
            "Training Epoch 10 loss:  tensor(3485.3979, grad_fn=<DivBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6d6057601ec7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mtraining_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"/content/drive/MyDrive/low-rank-expectile/checkpoints/model_checkpoint_epoch648.pt\")\n",
        "model.load_state_dict(checkpoint['Model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['Optimizer_state_dict'])\n",
        "loss = checkpoint['Loss']\n",
        "print(optimizer.state_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5MVpgtzzVMm",
        "outputId": "f04a520b-9ff8-43ba-e824-63e6d1975510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Optimizer.state_dict of Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")>\n"
          ]
        }
      ]
    }
  ]
}