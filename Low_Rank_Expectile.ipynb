{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1IfzZyH0SMUQhtWlt6FlyzgemIO6JtiHl",
      "authorship_tag": "ABX9TyOd5en96iZ/6I3ytoLOH42A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haytham918/low-rank-expectile/blob/main/Low_Rank_Expectile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "saCLAZMMxjWH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import matplotlib as plot\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv(\"/content/drive/MyDrive/low-rank-expectile/heartrate_seconds_merged.csv\")\n",
        "# Convert the 'Time' column to datetime format\n",
        "df['Time'] = pd.to_datetime(df['Time'])\n"
      ],
      "metadata": {
        "id": "IXJmn6cF1342"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_tenmin_df = df.groupby(['Id', pd.Grouper(key='Time', freq='5T')])['Value'].mean().unstack()\n",
        "user_tenmin_matrix = user_tenmin_df.values\n",
        "# print(user_tenmin_df)"
      ],
      "metadata": {
        "id": "U0Y7-t7pCfQ0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan_matrix = np.isnan(user_tenmin_matrix)\n",
        "print(\"Matrix Entry Number: \", user_tenmin_matrix.shape[0] * user_tenmin_matrix.shape[1])\n",
        "print(\"Nan Count: \", np.sum(nan_matrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHynihEq3T9Z",
        "outputId": "ee6cd3e7-9a39-406b-c1ec-76a24ad63b73"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Entry Number:  123718\n",
            "Nan Count:  56200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into trainig/validation and exclude missing values\n",
        "train_data, val_data, train_mask, val_mask = train_test_split(user_tenmin_matrix, nan_matrix, test_size=0.2, random_state=445)\n",
        "\n",
        "\n",
        "# Create Tensors based on train/val data\n",
        "train_tensor = torch.tensor(train_data, dtype=torch.float32)\n",
        "val_tensor = torch.tensor(val_data, dtype=torch.float32)\n",
        "\n",
        "\n",
        "# Model definition\n",
        "class LRModel(nn.Module):\n",
        "  def __init__(self, number_users, number_times, rank):\n",
        "    super().__init__()\n",
        "    self.user_factors = nn.Embedding(number_users, rank)\n",
        "    self.times_factors = nn.Embedding(number_times, rank)\n",
        "\n",
        "    self.user_bias = nn.Embedding(number_users, 1)\n",
        "    self.times_bias = nn.Embedding(number_times, 1)\n",
        "\n",
        "    # Initializing the bias terms to zeros\n",
        "    self.user_bias.weight.data.fill_(0.)\n",
        "    self.times_bias.weight.data.fill_(0.)\n",
        "\n",
        "\n",
        "  # Define forward propagation\n",
        "  def forward(self, user, times):\n",
        "    # print(self.user_factors(user).shape)\n",
        "    # print(self.times_factors(times).shape)\n",
        "    pred = self.user_factors(user) * self.times_factors(times)\n",
        "    pred = pred.sum(1, keepdim=False)\n",
        "    pred += self.user_bias(user).squeeze() + self.times_bias(times).squeeze()\n",
        "    return pred\n",
        "\n",
        "# Define Loss function excluding missing values\n",
        "def loss_func(predicted, actual, mask):\n",
        "    # print(predicted.shape, actual.shape, mask.shape)\n",
        "    invert_mask = ~mask\n",
        "    # print(predicted[invert_mask].shape, actual[invert_mask].shape)\n",
        "    loss = nn.MSELoss()\n",
        "    return loss(predicted[invert_mask].view(-1), actual[invert_mask].view(-1))\n",
        "\n",
        "# Define parameters in our case\n",
        "number_users, number_times = train_data.shape\n",
        "rank = 6\n",
        "model = LRModel(number_users, number_times, rank)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Epochs and CheckpointPath\n",
        "number_epochs = 800\n",
        "\n",
        "global_best_loss = float('inf')\n",
        "best_epoch = 0\n",
        "\n",
        "print(val_mask.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWwzjaBHWdVR",
        "outputId": "da6406ef-014c-4a7e-c81c-493138905466"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 8837)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "for epoch in range(number_epochs):\n",
        "  user_indices = torch.arange(number_users).repeat_interleave(number_times)\n",
        "  time_indices = torch.arange(number_times).repeat(number_users)\n",
        "  output = model(user_indices, time_indices)\n",
        "\n",
        "  # Calculate loss\n",
        "  train_tensor_flat = train_tensor.view(-1)\n",
        "  train_mask_flat = train_mask.reshape(-1)\n",
        "  training_loss = loss_func(output, train_tensor_flat, train_mask_flat)\n",
        "\n",
        "  # Backward\n",
        "  optimizer.zero_grad()\n",
        "  training_loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    validation_num_user, validation_num_times = val_tensor.shape\n",
        "    validation_user_indices = torch.arange(validation_num_user).repeat_interleave(validation_num_times)\n",
        "    validation_time_indices = torch.arange(validation_num_times).repeat(validation_num_user)\n",
        "    validation_output = model(validation_user_indices, validation_time_indices)\n",
        "    validation_loss = loss_func(validation_output, val_tensor.view(-1), val_mask.reshape(-1))\n",
        "\n",
        "  # print(f\"Epoch [{epoch + 1}/{number_epochs}]: Training Loss: {training_loss.item()}; Validation Loss: {validation_loss.item()}\")\n",
        "\n",
        "  if validation_loss < global_best_loss:\n",
        "      global_best_loss = validation_loss\n",
        "      best_epoch = epoch\n",
        "      torch.save({\"Epoch\": epoch, \"Model_state_dict\": model.state_dict(), \"Optimizer_state_dict\": optimizer.state_dict(), \"Loss\": validation_loss},\n",
        "                 f\"/content/drive/MyDrive/low-rank-expectile/checkpoints/model_checkpoint_epoch{epoch}.pt\")\n",
        "\n",
        "print(\"Best Validation Epoch: \", best_epoch + 1)\n",
        "print(\"Best Validation Loss: \", global_best_loss)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekyhksG0W7lA",
        "outputId": "c4dcec69-693a-4533-dff8-2d40a97ab2b7"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation Epoch:  297\n",
            "Best Validation Loss:  tensor(261.4429)\n"
          ]
        }
      ]
    }
  ]
}